{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "951c88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import load_dataset\n",
    "from enum import Enum\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import evaluate\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2bdd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = 'data/bioc/json/step_2_span_clf'\n",
    "\n",
    "class DatasetSplit(Enum):\n",
    "    train = 0\n",
    "    validation = 1\n",
    "    test = 2\n",
    "    \n",
    "class PicoType(Enum):\n",
    "    PARTICIPANTS = 4\n",
    "    INTERVENTIONS = 2\n",
    "    OUTCOMES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059e87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Span:\n",
    "    def __init__(self, start, length):\n",
    "        self.start = start\n",
    "        self.length = length\n",
    "        self.end = self.start + self.length\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Span(start={self.start}, length={self.length})'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.start, int(self.length)) == (other.start, int(other.length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b0f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spans_from_labels(label_sequence, pico_type_value):\n",
    "    span_start = [0 for l in label_sequence]\n",
    "    span_length = [0.0 for l in label_sequence]\n",
    "    labels = [pico_type_value&label if label > 0 else 0 for label in label_sequence]\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if label > 0:\n",
    "            if i==0 or labels[i-1] <= 0:\n",
    "                span_start[i] = 1\n",
    "                start = i\n",
    "            span_length[start] += 1\n",
    "            \n",
    "    spans = []\n",
    "    for i in range(len(span_start)):\n",
    "        if span_start[i]:\n",
    "            s = Span(start=i, length=span_length[i])\n",
    "            spans.append(s)\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0657b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pred_single_sample(prediction, reference):\n",
    "    tp, fp, fn = 0.0, 0.0, 0.0\n",
    "    prediction.sort(reverse=False, key=lambda x: x.start)\n",
    "    reference.sort(reverse=False, key=lambda x: x.start)\n",
    "    pi, ri = 0, 0\n",
    "    while pi < len(prediction) and ri < len(reference):\n",
    "        span_pred, span_ref = prediction[pi], reference[ri]\n",
    "        if span_pred == span_ref:\n",
    "            pi += 1\n",
    "            ri += 1\n",
    "            tp += 1\n",
    "        elif span_pred.start < span_ref.start:\n",
    "            pi += 1\n",
    "            fp += 1\n",
    "        else:\n",
    "            ri += 1\n",
    "            fn += 1\n",
    "\n",
    "    fp += len(prediction) - pi\n",
    "    fn += len(reference) - ri\n",
    "    \n",
    "    return tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3553f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self, tp=0, fp=0, fn=0):\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "        self.precision, self.recall, self.f1 = 0, 0, 0\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        tp = self.tp + other.tp\n",
    "        fp = self.fp + other.fp\n",
    "        fn = self.fn + other.fn\n",
    "        return ConfusionMatrix(tp, fp, fn)\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.tp / (self.tp + self.fp) if self.tp else 0\n",
    "        recall = self.tp / (self.tp + self.fn) if self.tp else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if self.tp else 0\n",
    "        self.precision, self.recall, self.f1 = precision, recall, f1\n",
    "\n",
    "    def __repr__(self):\n",
    "        self.compute()\n",
    "\n",
    "        return (\n",
    "            f' tp: {self.tp}\\n'\n",
    "            f' fp: {self.fp}\\n'\n",
    "            f' fn: {self.fn}\\n'\n",
    "            f' precsion: {self.precision*100:.2f}\\n'\n",
    "            f' recall: {self.recall*100:.2f}\\n'\n",
    "            f' f1: {self.f1*100:.2f}\\n\\n'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a441630b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/gzhang/.cache/huggingface/datasets/json/default-deaedfaba8add16c/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d67f5b75b6c4c2f939e4f3b4b6871c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_nlp = load_dataset(\n",
    "    'json',\n",
    "    data_files = {\n",
    "        'train': os.path.join(INPUT_FOLDER, 'test_pico_spans.json'), # not used\n",
    "        'validation': os.path.join(INPUT_FOLDER, 'test_pico_spans.json'), # not used\n",
    "        'test': os.path.join(INPUT_FOLDER, 'test_pico_spans.json')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd57134",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = ebm_nlp['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331d8b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3b5302b43543aa91592a8aad611486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participants_metric = ConfusionMatrix()\n",
    "interventions_metric = ConfusionMatrix()\n",
    "outcomes_metric = ConfusionMatrix()\n",
    "all_metric = ConfusionMatrix()\n",
    "\n",
    "progress_bar = tqdm(range(len(val)))\n",
    "for i in range(len(val)):\n",
    "    original_labels = val['original_labels'][i]\n",
    "    result_dict = val['pico_elements'][i]\n",
    "    for pico_type in list(PicoType):\n",
    "        records = result_dict[pico_type.name]\n",
    "        prediction = [\n",
    "            Span(start=r['span_start'], length =r['span_length'])\n",
    "            for r in records\n",
    "            if r['confidence'] > 0.5\n",
    "        ] if records else []\n",
    "        reference = extract_spans_from_labels(original_labels, pico_type.value)\n",
    "        tp, fp, fn = eval_pred_single_sample(prediction, reference)\n",
    "        batch_result = ConfusionMatrix(tp, fp, fn)\n",
    "        all_metric += batch_result\n",
    "        if pico_type == PicoType.PARTICIPANTS:\n",
    "            participants_metric += batch_result\n",
    "        if pico_type == PicoType.INTERVENTIONS:\n",
    "            interventions_metric += batch_result\n",
    "        if pico_type == PicoType.OUTCOMES:\n",
    "            outcomes_metric += batch_result       \n",
    "    progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da391d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " tp: 2038.0\n",
       " fp: 1772.0\n",
       " fn: 2164.0\n",
       " precsion: 53.49\n",
       " recall: 48.50\n",
       " f1: 50.87\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline:         p .497, r .412, f1 .450\n",
    "all_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ed8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_FOLDER = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0804e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/gzhang/.cache/huggingface/datasets/json/default-3e98f4a6402f7410/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87de260ebb24c43b017eb5de720af35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline = load_dataset(\n",
    "    'json',\n",
    "    data_files = {\n",
    "        'train': os.path.join(BASELINE_FOLDER, 'test_baseline_pred.json'), # not used\n",
    "        'validation': os.path.join(BASELINE_FOLDER, 'test_baseline_pred.json'),\n",
    "        'test': os.path.join(BASELINE_FOLDER, 'test_baseline_pred.json')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6fb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_val = baseline['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd023b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b505167a0b49e8875cfd294aa0a024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_participants_metric = ConfusionMatrix()\n",
    "baseline_interventions_metric = ConfusionMatrix()\n",
    "baseline_outcomes_metric = ConfusionMatrix()\n",
    "baseline_all_metric = ConfusionMatrix()\n",
    "\n",
    "progress_bar = tqdm(range(len(val)))\n",
    "for i in range(len(val)):\n",
    "    reference = baseline_val['original_labels'][i]\n",
    "    prediction = baseline_val['pico_pred'][i]\n",
    "    for pico_type in list(PicoType):\n",
    "        records = result_dict[pico_type.name]\n",
    "        pred = extract_spans_from_labels(prediction, pico_type.value)\n",
    "        ref = extract_spans_from_labels(reference, pico_type.value)\n",
    "        tp, fp, fn = eval_pred_single_sample(pred, ref)\n",
    "        batch_result = ConfusionMatrix(tp, fp, fn)\n",
    "        baseline_all_metric += batch_result\n",
    "        if pico_type == PicoType.PARTICIPANTS:\n",
    "            baseline_participants_metric += batch_result\n",
    "        if pico_type == PicoType.INTERVENTIONS:\n",
    "            baseline_interventions_metric += batch_result\n",
    "        if pico_type == PicoType.OUTCOMES:\n",
    "            baseline_outcomes_metric += batch_result       \n",
    "    progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1255f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " tp: 1731.0\n",
       " fp: 1752.0\n",
       " fn: 2471.0\n",
       " precsion: 49.70\n",
       " recall: 41.19\n",
       " f1: 45.05\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_all_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3730bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
